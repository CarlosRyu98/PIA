{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YenH_9hJbFk1"
   },
   "source": [
    "# Práctica 4: Redes Neuronales Convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbVhjPpzn6BM"
   },
   "source": [
    "Importa las librerías que vayas a necesitar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T00:11:56.338306Z",
     "iopub.status.busy": "2020-09-23T00:11:56.337617Z",
     "iopub.status.idle": "2020-09-23T00:12:03.150200Z",
     "shell.execute_reply": "2020-09-23T00:12:03.150753Z"
    },
    "id": "dzLKpmZICaWN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "## Seleccionar dataset e importarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLdCchMdCaWQ"
   },
   "source": [
    "Busca en la web de Kaggle (o en cualquier otra) un dataset de cualquier tema que te interese. Procura que no sea excesivamente grande para evitar un tiempo de entrenamiento mayor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2441 files belonging to 8 classes.\n",
      "Found 390 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "logos_train = tf.keras.utils.image_dataset_from_directory(directory=\"04_Data/Car_Brand_Logos/Train/\")\n",
    "logos_val = tf.keras.utils.image_dataset_from_directory(directory=\"04_Data/Car_Brand_Logos/Test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brm0b_KACaWX"
   },
   "source": [
    "## Exploramos el dataset\n",
    "\n",
    "Exploramos el formato del dataset: forma, número de elementos, número de \"clases\" finales..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T00:12:04.638892Z",
     "iopub.status.busy": "2020-09-23T00:12:04.638288Z",
     "iopub.status.idle": "2020-09-23T00:12:04.641162Z",
     "shell.execute_reply": "2020-09-23T00:12:04.640615Z"
    },
    "id": "iJmPr5-ACaWn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyundai',\n",
       " 'lexus',\n",
       " 'mazda',\n",
       " 'mercedes',\n",
       " 'opel',\n",
       " 'skoda',\n",
       " 'toyota',\n",
       " 'volkswagen']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logos_train.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES6uQoLKCaWr"
   },
   "source": [
    "## Preprocesamiento del dataset\n",
    "\n",
    "Haz las operaciones oportunas sobre el set de datos (en caso de ser necesarias). Por ejemplo, si se trata de imágenes en color y quieres trabajar en blanco y negro cambia sus dimensiones. O si son valores entre 0 y 255 escalalos al intervalo 0-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 8\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59veuiEZCaW4"
   },
   "source": [
    "## Construir el Modelo\n",
    "\n",
    "Construir la red neuronal requiere configurar las capas del modelo y luego compilar el modelo. Para ello, recuerda que puedes revisar el ejemplo realizado por Marcos y Carmen (Conv2D) o Ainhoa y Carlos (Conv3D) en la práctica 2, además de tener en cuenta los siguientes aspectos importantes:\n",
    "\n",
    "*   Según nos adentramos en capas más profundas, el tamaño de las imágenes se debería ir reescalando por uno menor (utilizando la **capa MaxPool**)\n",
    "*   Según nos adentramos en capas más profundas, la cantidad de capas convolucionales seguidas ha de ser mayor para que detecten patrones más complejos.\n",
    "*   El final de la red será una **capa Flatten** para \"aplanar\" las imágenes resultantes de capas anteriores, seguido de tantas **capas Dense** como necesites.\n",
    "*   Recuerda dejar en la última capa densa tantas neuronas como \"clases\" tengas que diferenciar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T00:12:05.902968Z",
     "iopub.status.busy": "2020-09-23T00:12:05.900405Z",
     "iopub.status.idle": "2020-09-23T00:12:07.650519Z",
     "shell.execute_reply": "2020-09-23T00:12:07.650995Z"
    },
    "id": "9ODch-OFCaW4"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Conv2D(4, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gut8A_7rCaW6"
   },
   "source": [
    "### Compilamos el modelo\n",
    "\n",
    "Antes de que el modelo este listo para entrenar , se necesitan algunas configuraciones mas: el optimizador, la función de coste o las métricas a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T00:12:07.663857Z",
     "iopub.status.busy": "2020-09-23T00:12:07.663044Z",
     "iopub.status.idle": "2020-09-23T00:12:07.670764Z",
     "shell.execute_reply": "2020-09-23T00:12:07.670104Z"
    },
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "## Entrenar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T00:12:07.675211Z",
     "iopub.status.busy": "2020-09-23T00:12:07.674345Z",
     "iopub.status.idle": "2020-09-23T00:12:36.454526Z",
     "shell.execute_reply": "2020-09-23T00:12:36.453882Z"
    },
    "id": "xvwvpA64CaW_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "77/77 [==============================] - 31s 387ms/step - loss: 2.0690 - accuracy: 0.1585 - val_loss: 2.0276 - val_accuracy: 0.1897\n",
      "Epoch 2/25\n",
      "77/77 [==============================] - 30s 376ms/step - loss: 1.8077 - accuracy: 0.3314 - val_loss: 1.6000 - val_accuracy: 0.4487\n",
      "Epoch 3/25\n",
      "77/77 [==============================] - 28s 356ms/step - loss: 1.4096 - accuracy: 0.5272 - val_loss: 1.4864 - val_accuracy: 0.5513\n",
      "Epoch 4/25\n",
      "77/77 [==============================] - 28s 356ms/step - loss: 1.1505 - accuracy: 0.6104 - val_loss: 1.5540 - val_accuracy: 0.5436\n",
      "Epoch 5/25\n",
      "77/77 [==============================] - 28s 353ms/step - loss: 0.9399 - accuracy: 0.6903 - val_loss: 1.7019 - val_accuracy: 0.5667\n",
      "Epoch 6/25\n",
      "77/77 [==============================] - 28s 357ms/step - loss: 0.7475 - accuracy: 0.7456 - val_loss: 1.4038 - val_accuracy: 0.6154\n",
      "Epoch 7/25\n",
      "77/77 [==============================] - 28s 356ms/step - loss: 0.6118 - accuracy: 0.7923 - val_loss: 1.4419 - val_accuracy: 0.6256\n",
      "Epoch 8/25\n",
      "77/77 [==============================] - 28s 355ms/step - loss: 0.4937 - accuracy: 0.8279 - val_loss: 1.7085 - val_accuracy: 0.6179\n",
      "Epoch 9/25\n",
      "77/77 [==============================] - 28s 353ms/step - loss: 0.3980 - accuracy: 0.8726 - val_loss: 1.9395 - val_accuracy: 0.6410\n",
      "Epoch 10/25\n",
      "77/77 [==============================] - 28s 351ms/step - loss: 0.3347 - accuracy: 0.8902 - val_loss: 2.3748 - val_accuracy: 0.6308\n",
      "Epoch 11/25\n",
      "77/77 [==============================] - 28s 354ms/step - loss: 0.2902 - accuracy: 0.9050 - val_loss: 2.3262 - val_accuracy: 0.6487\n",
      "Epoch 12/25\n",
      "77/77 [==============================] - 28s 359ms/step - loss: 0.2685 - accuracy: 0.9095 - val_loss: 2.3550 - val_accuracy: 0.6487\n",
      "Epoch 13/25\n",
      "77/77 [==============================] - 28s 353ms/step - loss: 0.2496 - accuracy: 0.9205 - val_loss: 2.7121 - val_accuracy: 0.6641\n",
      "Epoch 14/25\n",
      "77/77 [==============================] - 28s 358ms/step - loss: 0.2119 - accuracy: 0.9304 - val_loss: 2.4479 - val_accuracy: 0.6436\n",
      "Epoch 15/25\n",
      "77/77 [==============================] - 28s 356ms/step - loss: 0.1634 - accuracy: 0.9418 - val_loss: 2.5946 - val_accuracy: 0.6615\n",
      "Epoch 16/25\n",
      "77/77 [==============================] - 28s 350ms/step - loss: 0.1519 - accuracy: 0.9545 - val_loss: 2.9917 - val_accuracy: 0.6462\n",
      "Epoch 17/25\n",
      "77/77 [==============================] - 28s 358ms/step - loss: 0.1243 - accuracy: 0.9623 - val_loss: 2.8954 - val_accuracy: 0.6513\n",
      "Epoch 18/25\n",
      "77/77 [==============================] - 28s 354ms/step - loss: 0.1159 - accuracy: 0.9639 - val_loss: 3.3485 - val_accuracy: 0.6410\n",
      "Epoch 19/25\n",
      "77/77 [==============================] - 29s 363ms/step - loss: 0.1450 - accuracy: 0.9558 - val_loss: 3.2965 - val_accuracy: 0.6513\n",
      "Epoch 20/25\n",
      "77/77 [==============================] - 28s 352ms/step - loss: 0.1110 - accuracy: 0.9656 - val_loss: 3.3189 - val_accuracy: 0.6462\n",
      "Epoch 21/25\n",
      "77/77 [==============================] - 27s 348ms/step - loss: 0.1262 - accuracy: 0.9676 - val_loss: 3.3270 - val_accuracy: 0.6462\n",
      "Epoch 22/25\n",
      "77/77 [==============================] - 27s 348ms/step - loss: 0.1205 - accuracy: 0.9631 - val_loss: 3.0417 - val_accuracy: 0.6641\n",
      "Epoch 23/25\n",
      "77/77 [==============================] - 27s 349ms/step - loss: 0.1215 - accuracy: 0.9635 - val_loss: 2.9526 - val_accuracy: 0.6769\n",
      "Epoch 24/25\n",
      "77/77 [==============================] - 29s 362ms/step - loss: 0.0862 - accuracy: 0.9762 - val_loss: 3.4412 - val_accuracy: 0.6513\n",
      "Epoch 25/25\n",
      "77/77 [==============================] - 30s 378ms/step - loss: 0.0732 - accuracy: 0.9783 - val_loss: 3.5338 - val_accuracy: 0.6538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x235034edf70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    logos_train,\n",
    "    validation_data=logos_val,\n",
    "    epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEw4bZgGCaXB"
   },
   "source": [
    "## Evaluar Exactitud\n",
    "\n",
    "Comparar el rendimiento del modelo sobre el dataset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T00:12:36.459549Z",
     "iopub.status.busy": "2020-09-23T00:12:36.458790Z",
     "iopub.status.idle": "2020-09-23T00:12:37.082116Z",
     "shell.execute_reply": "2020-09-23T00:12:37.082547Z"
    },
    "id": "VflXLEeECaXC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 2s 116ms/step - loss: 3.5338 - accuracy: 0.6538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.5337958335876465, 0.6538461446762085]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(logos_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsoS7CPDCaXH"
   },
   "source": [
    "## Hacer predicciones\n",
    "\n",
    "Con el modelo entrenado probar a hacer predicciones sobre alguna imagen concreta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T00:12:37.087029Z",
     "iopub.status.busy": "2020-09-23T00:12:37.086398Z",
     "iopub.status.idle": "2020-09-23T00:12:37.407345Z",
     "shell.execute_reply": "2020-09-23T00:12:37.406539Z"
    },
    "id": "Gl91RPhdCaXI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para comprobar si el formato de las imágenes es correcto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing class directory  hyundai\n",
      "processing class directory  lexus\n",
      "processing class directory  mazda\n",
      "processing class directory  mercedes\n",
      "processing class directory  opel\n",
      "processing class directory  skoda\n",
      "processing class directory  toyota\n",
      "processing class directory  volkswagen\n",
      " no improper image files were found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imghdr\n",
    "\n",
    "def check_images( s_dir, ext_list):\n",
    "    bad_images=[]\n",
    "    bad_ext=[]\n",
    "    s_list= os.listdir(s_dir)\n",
    "    for klass in s_list:\n",
    "        klass_path=os.path.join (s_dir, klass)\n",
    "        print ('processing class directory ', klass)\n",
    "        if os.path.isdir(klass_path):\n",
    "            file_list=os.listdir(klass_path)\n",
    "            for f in file_list:               \n",
    "                f_path=os.path.join (klass_path,f)\n",
    "                tip = imghdr.what(f_path)\n",
    "                if ext_list.count(tip) == 0:\n",
    "                    bad_images.append(f_path)\n",
    "                if os.path.isfile(f_path):\n",
    "                    try:\n",
    "                        img=plt.imread(f_path)\n",
    "                        shape=img.shape\n",
    "                    except:\n",
    "                        print('file ', f_path, ' is not a valid image file')\n",
    "                        bad_images.append(f_path)\n",
    "                else:\n",
    "                    print('*** fatal error, you a sub directory ', f, ' in class directory ', klass)\n",
    "        else:\n",
    "            print ('*** WARNING*** you have files in ', s_dir, ' it should only contain sub directories')\n",
    "    return bad_images, bad_ext\n",
    "\n",
    "source_dir = \"04_Data/Car_Brand_Logos/Train\"\n",
    "good_exts=['jpg', 'png', 'jpeg', 'gif', 'bmp' ] # list of acceptable extensions\n",
    "bad_file_list, bad_ext_list=check_images(source_dir, good_exts)\n",
    "if len(bad_file_list) !=0:\n",
    "    print('improper image files are listed below')\n",
    "    for i in range (len(bad_file_list)):\n",
    "        print (bad_file_list[i])\n",
    "else:\n",
    "    print(' no improper image files were found')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
