{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR LOGARÍTMICO CUADRÁTICO MEDIO RMSLE (Mean Squared Logarithmic Error)\n",
    "\n",
    "## Formula del RMSLE\n",
    "\n",
    "RMSLE se usa cuando y tiene una larga cola de distribución , o cuando nos interesa el ratio de los valores verdaderos y los valores que se han predecido.\n",
    "1 (la constante ) es añadido para evitar divergencia cuando y es igual a 0.\n",
    "\n",
    "## Mecanismo:\n",
    "\n",
    "    Es solo un error cuadrático medio (MSE) calculado en escala logarítmica. De hecho, para calcularlo, tomamos un logaritmo de nuestras predicciones y los valores objetivo, y calculamos el error cuadrático medio (MSE) entre ellos.\n",
    "\n",
    "    Los objetivos generalmente no son negativos pero pueden ser iguales a 0, y el logaritmo de 0 no está definido. Por tanto se agrega una constante a las predicciones y los objetivos antes de aplicar la operación logarítmica.Esta constante también se puede definir para que sea diferente a uno según el problema que queramos resolver.\n",
    "\n",
    "    Esta métrica se usa generalmente en la misma situación que MSPE (Error de porcentaje cuadrático medio) y MAPE(Error porcentual absoluto medio), ya que también conlleva errores relativos más que errores absolutos.\n",
    "\n",
    "\n",
    "## Funcionalidad:\n",
    "\n",
    "    La expresión\n",
    "    log(pi+1)−log(ai+1)\n",
    "\n",
    "    tambien puede ser escrita así:\n",
    "    log((pi+1)/(ai+1))\n",
    "\n",
    "![aqui va la sintaxis](https://cdn-images-1.medium.com/max/800/1*VjNfaSRuj3FIMcKA0yJAGg.png)\n",
    "\n",
    "    MSLE mide el ratio de los valores reales y predichos.\n",
    "\n",
    "    MSLE es preferible cuando:\n",
    "\n",
    "        * Los objetivos crecen exponencialmente (por ejemplo haciendo un conteo de población)\n",
    "        * Nos interesa mas el porcentaje de errores que el valor absoluto de errores.\n",
    "        * Hay un gran rango de valores en las variables objetivo y no queremos penalizar grandes diferencias cuando los valores predichos y reales son numeros grandes.\n",
    "        * MSLE penaliza una infraestimación frente a una sobreestimación.\n",
    "        \n",
    "Vamos a imaginar 2 casos de predicciones,\n",
    "\n",
    "    Caso-1: nuestro modelo tiene una prediccion de 30 cuando el numero actual es 40\n",
    "\n",
    "    Caso-2: nuestro modelo tiene una prediccion de 300 cuando el numero actual es 400\n",
    "        Con el error cuadrático medio el segundo resultado es puntuado como 10 veces mas que el primer resultado\n",
    "        En cambio con el error logaritmico cuadrático medio los 2 resultados son puntuados igual.\n",
    "        MSLE tiene en cuenta el ratio de cambio.\n",
    "\n",
    "Si observamos el siguiente ejemplo:\n",
    "\n",
    "    Caso-3 :\n",
    "\n",
    "        Prediccion = 600, Actual = 1000 (la diferencia es de 400)\n",
    "\n",
    "    RMSE = 400, RMSLogE = 0.5108\n",
    "\n",
    "    Caso-4 :\n",
    "\n",
    "        Prediccion = 1400 , Actual = 1000 (la diferencia es de 400)\n",
    "\n",
    "    RMSE = 400, RMSLogE = 0.3365\n",
    "\n",
    "    Cuando las diferencias son las mismas entre los valores predichos y reales:\n",
    "        El error cuadrático medio las trata de la misma forma en ambos casos ,\n",
    "        sin embargo el error logaritmico cuadrático medio penaliza la baja estimación mas que la sobreestimación.\n",
    "\n",
    "    A menudo, penalizar una baja estimacion mas que una sobreestimacion es importante a la hora de predicciones sobre ventas y demandas de inventario.\n",
    "    Sería preferible tener inventario extra a no ser capaz de proveer un producto tanto como se demanda.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- - - - - - - - - - - - -\n",
    "\n",
    "\n",
    "URLs:\n",
    "\n",
    "https://towardsdatascience.com/11-evaluation-metrics-data-scientists-should-be-familiar-with-lessons-from-a-high-rank-kagglers-8596f75e58a7#5185\n",
    "\n",
    "https://hrngok.github.io/posts/metrics/\n",
    "\n",
    "https://sitiobigdata.com/2019/05/27/modelos-de-machine-learning-metricas-de-regresion-mse-parte-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error logaritmico cuadrático medio:\n",
      "0.024231082550315173\n",
      "Error cuadrático medio:\n",
      "0.27799999999999997\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "\n",
    "y_true = [1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "y_pred = [0.9, 1.7, 3.0, 2.0, 2.7]\n",
    "\n",
    "msle =(mean_squared_log_error(y_true,y_pred))\n",
    "mse=(mean_squared_error(y_true,y_pred))\n",
    "print(\"Error logaritmico cuadrático medio:\")\n",
    "print(msle)\n",
    "print(\"Error cuadrático medio:\")\n",
    "print(mse)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ef8c08b800cfe7a39ab89adcf703ee7065445770650f99cd00596bc349a0a52"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
